{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/ner_jsonl_dataset.pickle', 'rb') as fp:\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>{'entities': [(48, 54, 'geo'), (77, 81, 'geo')...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>{'entities': [(0, 7, 'gpe'), (87, 96, 'tim'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Beirut , a string of officials voiced their...</td>\n",
       "      <td>{'entities': [(3, 9, 'geo'), (68, 82, 'org'), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She was a longtime member of the Zapatista mov...</td>\n",
       "      <td>{'entities': [(33, 42, 'geo')]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday 's violence came a day after Iraqi fo...</td>\n",
       "      <td>{'entities': [(0, 8, 'tim'), (38, 43, 'gpe'), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  In Beirut , a string of officials voiced their...   \n",
       "3  She was a longtime member of the Zapatista mov...   \n",
       "4  Saturday 's violence came a day after Iraqi fo...   \n",
       "\n",
       "                                                   1  \n",
       "0  {'entities': [(48, 54, 'geo'), (77, 81, 'geo')...  \n",
       "1  {'entities': [(0, 7, 'gpe'), (87, 96, 'tim'), ...  \n",
       "2  {'entities': [(3, 9, 'geo'), (68, 82, 'org'), ...  \n",
       "3                    {'entities': [(33, 42, 'geo')]}  \n",
       "4  {'entities': [(0, 8, 'tim'), (38, 43, 'gpe'), ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=None\n",
    "new_model_name=\"ner_model\" \n",
    "output_dir=\"../models/ner_model\"\n",
    "n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "if model is not None:\n",
    "    nlp = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Ner Pipeline to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entity recognizer to model if it's not in the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.add_label(\"geo\")\n",
    "ner.add_label(\"tim\")\n",
    "ner.add_label(\"gpe\")\n",
    "ner.add_label(\"per\")\n",
    "ner.add_label(\"org\")\n",
    "ner.add_label(\"art\")\n",
    "ner.add_label(\"nat\")\n",
    "ner.add_label(\"eve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/spacy/language.py:639: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  **kwargs\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/language.py:639: UserWarning: [W034] Please install the package spacy-lookups-data in order to include the default lexeme normalization table for the language 'en'.\n",
      "  **kwargs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 263921.4421927165}\n",
      "Losses {'ner': 250241.47440917173}\n",
      "Losses {'ner': 245974.20855903166}\n",
      "Losses {'ner': 243044.41729112464}\n",
      "Losses {'ner': 240475.7237344407}\n",
      "Losses {'ner': 239396.98484679245}\n",
      "Losses {'ner': 237281.7715465767}\n",
      "Losses {'ner': 236557.4139251585}\n",
      "Losses {'ner': 235453.03034034223}\n",
      "Losses {'ner': 234552.29836780188}\n",
      "Losses {'ner': 233040.7541645741}\n",
      "Losses {'ner': 233640.52691602003}\n",
      "Losses {'ner': 232447.65078567847}\n",
      "Losses {'ner': 231313.78144394435}\n",
      "Losses {'ner': 231634.7244849312}\n",
      "Losses {'ner': 230373.0302320144}\n",
      "Losses {'ner': 229843.67416371347}\n",
      "Losses {'ner': 229590.31484822437}\n",
      "Losses {'ner': 229444.5880639447}\n",
      "Losses {'ner': 229136.5777237773}\n",
      "Losses {'ner': 228924.77029033474}\n",
      "Losses {'ner': 229455.6061231999}\n",
      "Losses {'ner': 228028.6616101425}\n",
      "Losses {'ner': 228312.4036155009}\n",
      "Losses {'ner': 228207.69952982935}\n",
      "Losses {'ner': 227154.39907296497}\n",
      "Losses {'ner': 226683.67879137257}\n",
      "Losses {'ner': 226812.369536981}\n",
      "Losses {'ner': 226659.6400351938}\n",
      "Losses {'ner': 226586.19738980857}\n",
      "Losses {'ner': 226302.40990263608}\n",
      "Losses {'ner': 226026.07853638628}\n",
      "Losses {'ner': 226156.27818920833}\n",
      "Losses {'ner': 225808.09514335115}\n",
      "Losses {'ner': 225965.2679322686}\n",
      "Losses {'ner': 225617.31546622864}\n",
      "Losses {'ner': 225055.1792412746}\n",
      "Losses {'ner': 225482.7885831861}\n",
      "Losses {'ner': 225427.9970582698}\n",
      "Losses {'ner': 225655.12487267813}\n",
      "Losses {'ner': 225285.12211878432}\n",
      "Losses {'ner': 225428.87238518108}\n",
      "Losses {'ner': 224898.85916771885}\n",
      "Losses {'ner': 223849.11098542323}\n",
      "Losses {'ner': 224745.18366597657}\n",
      "Losses {'ner': 223679.43050910725}\n",
      "Losses {'ner': 223955.6849460775}\n",
      "Losses {'ner': 223475.5384097986}\n",
      "Losses {'ner': 224182.36021912497}\n",
      "Losses {'ner': 223438.47270239436}\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "print(other_pipes)\n",
    "with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():  # only train NER\n",
    "    \n",
    "    warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "    \n",
    "    if model is None:\n",
    "        nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(dataset)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(dataset, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.2,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ../models/ner_model\n"
     ]
    }
   ],
   "source": [
    "# save model to output directory\n",
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.meta[\"name\"] = new_model_name  # rename model\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ../models/ner_model\n"
     ]
    }
   ],
   "source": [
    "# test the saved model\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's your turn\n",
    "\n",
    "Test out the model you just trained. Run the code Cell below and type your reviews in the widget, Have fun!ðŸŽ‰\n",
    "\n",
    "Here are some inspirations:\n",
    "\n",
    "- Obama was the president of USA.\n",
    "- The 1906 San Francisco earthquake was the biggest earthquake that has ever hit San Francisco on April 18, 1906\n",
    "- Next Monday is Christmas!\n",
    "\n",
    "Can you do better? Play around with the model hyperparameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The 1906 San Francisco earthquake was the biggest earthquake that has ever hit San Francisco on April 18, 1906\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The 1906 \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">geo</span>\n",
       "</mark>\n",
       " earthquake was the biggest earthquake that has ever hit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">geo</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    April 18, 1906\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">tim</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets\n",
    "\n",
    "doc2 = nlp2(sentence)\n",
    "displacy.render(doc2, style=\"ent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
